{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate Diversity by Distinct-n method\n",
    "\n",
    "## Hypothesis\n",
    "The Distinct-n score will increase with the dynamic pieces since the conversations are more diverse.\n",
    "\n",
    "## Distinct-n\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Get the current working directory\n",
    "current_dir = os.getcwd()\n",
    "\n",
    "# Change to root direction\n",
    "root_dir = os.path.dirname(os.path.dirname(os.path.dirname(os.path.dirname(current_dir))))\n",
    "os.chdir(root_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implementation of EAD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataset.experiments.diversity_with_without_dynamic_pieces.Distinct_n_score.distinct_n import distinct_n_sentence_level\n",
    "from dataset.experiments.diversity_with_without_dynamic_pieces.Distinct_n_score.distinct_n import distinct_n_corpus_level\n",
    "\n",
    "# Example usage\n",
    "conversations = [\n",
    "    [\"Hello, how are you?\", \"I am fine, thank you.\", \"And you?\", \"I'm good too.\"],\n",
    "    [\"What are you doing?\", \"Just reading a book.\", \"Which one?\", \"A mystery novel.\"],\n",
    "    # More conversations...\n",
    "]\n",
    "\n",
    "ead_metric = distinct_n_corpus_level(conversations, 2)  # For bigrams\n",
    "print(\"Distinct-n Metric:\", ead_metric)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Conversations with and without dynamic pieces\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "sys.path.append(str(root_dir))\n",
    "\n",
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "# Local Imports\n",
    "from dataset.chains.extraction_conversations import ExtractionConversationChain\n",
    "from utils.start_langsmith_tracing import start_langsmith_tracing\n",
    "\n",
    "start_langsmith_tracing(project_name=\"Experiment_EAD_Score\")\n",
    "user_profiles = []\n",
    "user_profiles_dir = 'dataset/userprofiles/train_user_profiles.jsonl'\n",
    "with open(user_profiles_dir, 'r') as file:\n",
    "    for line in file:\n",
    "        json_object = json.loads(line.strip())\n",
    "        user_profiles.append(json_object)\n",
    "\n",
    "user_profiles = user_profiles[:4] # Take only user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "# Helper Function\n",
    "def convert_conv_to_list_of_strings(conversation):\n",
    "    \"\"\"\n",
    "    converts the returned conversation to a list of strings of the turns\n",
    "    \"\"\"\n",
    "    conv = json.loads(conversation.content)['conversation']\n",
    "    conversation_list_of_strings = []\n",
    "    for turn in conv:\n",
    "        conversation_list_of_strings.append(str(list(turn.values())[0]))\n",
    "        \n",
    "    return conversation_list_of_strings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "extraction_conversation_chain = ExtractionConversationChain()\n",
    "\n",
    "all_distinct_n_scores_dynamic = []\n",
    "all_distinct_n_scores_not_dynamic = []\n",
    "\n",
    "for idx, user_profile in enumerate(user_profiles):\n",
    "    user_profile_df = pd.DataFrame(user_profile[\"user_profile\"])\n",
    "    user_profile_df = user_profile_df.iloc[idx*2]\n",
    "\n",
    "    print(\"========= NEW USER =========\")\n",
    "    print(user_profile_df)\n",
    "    print(\"==\")\n",
    "    distinct_n_scores_dynamic = []\n",
    "    distinct_n_scores_not_dynamic = []\n",
    "    \n",
    "    topic = user_profile_df[\"Main Category\"] + \"; \" + user_profile_df[\"Subcategory\"]\n",
    "    user_preference = user_profile_df[\"Main Category\"] + \"; \" + user_profile_df[\"Subcategory\"] + \"; \" + user_profile_df[\"Detail Category\"] + \"; \" + user_profile_df[\"Attributes\"]\n",
    "    \n",
    "    \n",
    "    if os.path.isfile(f\"dataset/experiments/diversity_with_without_dynamic_pieces/Distinct_n_score/pickle/conversations_dynamic_{idx}_v3.pkl\"):\n",
    "        with open(f\"dataset/experiments/diversity_with_without_dynamic_pieces/Distinct_n_score/pickle/conversations_dynamic_{idx}_v3.pkl\", 'rb') as file:\n",
    "            conversations_dynamic = pickle.load(file)\n",
    "            print(\"load existing\")\n",
    "        with open(f\"dataset/experiments/diversity_with_without_dynamic_pieces/Distinct_n_score/pickle/conversations_not_dynamic_{idx}_v3.pkl\", 'rb') as file:\n",
    "            conversations_not_dynamic = pickle.load(file)\n",
    "            print(\"load existing\")\n",
    "        with open(f\"dataset/experiments/diversity_with_without_dynamic_pieces/Distinct_n_score/pickle/metadatas_dynamic_{idx}_v3.pkl\", 'rb') as file:\n",
    "            metadatas_dynamic = pickle.load(file)\n",
    "            print(\"load existing\")\n",
    "        with open(f\"dataset/experiments/diversity_with_without_dynamic_pieces/Distinct_n_score/pickle/metadatas_not_dynamic_{idx}_v3.pkl\", 'rb') as file:\n",
    "            metadatas_not_dynamic = pickle.load(file)      \n",
    "            print(\"load existing\")\n",
    "    else:\n",
    "        # With dynamic pieces\n",
    "        conversations_dynamic = []\n",
    "        conversations_not_dynamic = []\n",
    "        metadatas_dynamic = []\n",
    "        metadatas_not_dynamic = []\n",
    "        for i in range(10):\n",
    "            if i == 0: # so that first sampled dynamic pieces are same to the ones in fixed dynamic pieces\n",
    "                conversation_dynamic, metadata_dynamic = extraction_conversation_chain.generate_one_conversation(topic=topic, user_preference=user_preference, random_seed=idx)\n",
    "                print(\"==== Metadata Dynamic =====\")\n",
    "                print(metadata_dynamic)\n",
    "                print(\"===========================\")\n",
    "                conv = convert_conv_to_list_of_strings(conversation_dynamic)\n",
    "                conversations_dynamic.append(conv)\n",
    "                metadatas_dynamic.append(metadata_dynamic)\n",
    "            else:\n",
    "                conversation_dynamic, metadata_dynamic = extraction_conversation_chain.generate_one_conversation(topic=topic, user_preference=user_preference, random_seed = None)\n",
    "                print(\"==== Metadata Dynamic =====\")\n",
    "                print(metadata_dynamic)\n",
    "                print(\"===========================\")                \n",
    "                conv = convert_conv_to_list_of_strings(conversation_dynamic)\n",
    "                conversations_dynamic.append(conv)\n",
    "                metadatas_dynamic.append(metadata_dynamic)\n",
    "\n",
    "        # Without dynamic pieces\n",
    "            conversation_not_dynamic, metadata_not_dynamic = extraction_conversation_chain.generate_one_conversation(topic=topic, user_preference=user_preference, random_seed=idx)\n",
    "            print(\"==== Metadata Not Dynamic =====\")\n",
    "            print(metadata_not_dynamic)\n",
    "            print(\"===========================\")            \n",
    "            conv = convert_conv_to_list_of_strings(conversation_not_dynamic)\n",
    "            conversations_not_dynamic.append(conv)\n",
    "            metadatas_not_dynamic.append(metadata_not_dynamic)\n",
    "\n",
    "\n",
    "        with open(f\"dataset/experiments/diversity_with_without_dynamic_pieces/Distinct_n_score/pickle/conversations_dynamic_{idx}_v3.pkl\", 'wb') as file:\n",
    "            pickle.dump(conversations_dynamic, file)\n",
    "        with open(f\"dataset/experiments/diversity_with_without_dynamic_pieces/Distinct_n_score/pickle/conversations_not_dynamic_{idx}_v3.pkl\", 'wb') as file:\n",
    "            pickle.dump(conversations_not_dynamic, file)\n",
    "        with open(f\"dataset/experiments/diversity_with_without_dynamic_pieces/Distinct_n_score/pickle/metadatas_dynamic_{idx}_v3.pkl\", 'wb') as file:\n",
    "            pickle.dump(metadatas_dynamic, file)\n",
    "        with open(f\"dataset/experiments/diversity_with_without_dynamic_pieces/Distinct_n_score/pickle/metadatas_not_dynamic_{idx}_v3.pkl\", 'wb') as file:\n",
    "            pickle.dump(metadatas_not_dynamic, file)   \n",
    "\n",
    "    \n",
    "\n",
    "    for i in range(len(conversations_dynamic)):\n",
    "        flattened_conversations_dynamic = [item.split() for sublist in conversations_dynamic[:i+1] for item in sublist]\n",
    "    \n",
    "        current_distinct_n_scores_dynamic = []\n",
    "        flattened_conversations_dynamic = [item for sublist in flattened_conversations_dynamic for item in sublist]\n",
    "        print(\"flattened_conversation_dynamic\")\n",
    "        print(flattened_conversations_dynamic)\n",
    "        ead_metric_dynamic_1 = distinct_n_sentence_level(flattened_conversations_dynamic, 1)  # For bigrams\n",
    "        print(\"Distinct-1 Dynamic Metric:\", ead_metric_dynamic_1)\n",
    "        current_distinct_n_scores_dynamic.append(ead_metric_dynamic_1)\n",
    "        ead_metric_dynamic_2 = distinct_n_sentence_level(flattened_conversations_dynamic, 2)  # For bigrams\n",
    "        print(\"Distinct-2 Dynamic Metric:\", ead_metric_dynamic_2)\n",
    "        current_distinct_n_scores_dynamic.append(ead_metric_dynamic_2)\n",
    "        ead_metric_dynamic_3 = distinct_n_sentence_level(flattened_conversations_dynamic, 3)  # For bigrams\n",
    "        print(\"Distinct-3 Dynamic Metric:\", ead_metric_dynamic_3)\n",
    "        current_distinct_n_scores_dynamic.append(ead_metric_dynamic_3)\n",
    "\n",
    "        distinct_n_scores_dynamic.append(current_distinct_n_scores_dynamic)\n",
    "\n",
    "    all_distinct_n_scores_dynamic.append(distinct_n_scores_dynamic)\n",
    "    \n",
    "\n",
    "    for i in range(len(conversations_not_dynamic)): \n",
    "        flattened_conversations_not_dynamic = [item.split() for sublist in conversations_not_dynamic[:i+1] for item in sublist]\n",
    "    \n",
    "        current_distinct_n_scores_not_dynamic = []\n",
    "        flattened_conversations_not_dynamic = [item for sublist in flattened_conversations_not_dynamic for item in sublist]\n",
    "        print(\"flattened_conversation_not_dynamic\")\n",
    "        print(flattened_conversations_not_dynamic)\n",
    "        ead_metric_not_dynamic_1 = distinct_n_sentence_level(flattened_conversations_not_dynamic, 1)  # For bigrams\n",
    "        print(\"Distinct-1 Dynamic Metric:\", ead_metric_not_dynamic_1)\n",
    "        current_distinct_n_scores_not_dynamic.append(ead_metric_not_dynamic_1)\n",
    "        ead_metric_not_dynamic_2 = distinct_n_sentence_level(flattened_conversations_not_dynamic, 2)  # For bigrams\n",
    "        print(\"Distinct-2 Dynamic Metric:\", ead_metric_not_dynamic_2)\n",
    "        current_distinct_n_scores_not_dynamic.append(ead_metric_not_dynamic_2)\n",
    "        ead_metric_not_dynamic_3 = distinct_n_sentence_level(flattened_conversations_not_dynamic, 3)  # For bigrams\n",
    "        print(\"Distinct-3 Dynamic Metric:\", ead_metric_not_dynamic_3)\n",
    "        current_distinct_n_scores_not_dynamic.append(ead_metric_not_dynamic_3)\n",
    "\n",
    "        distinct_n_scores_not_dynamic.append(current_distinct_n_scores_not_dynamic)\n",
    "\n",
    "    all_distinct_n_scores_not_dynamic.append(distinct_n_scores_not_dynamic)\n",
    "    print(\"==============================\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_distinct_n_scores_dynamic\n",
    "# len(conversations_dynamic)-1\n",
    "# conversations_dynamic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Distinct-1 Dynamic Metric: 0.45869947275922673\n",
    "Distinct-1 Not Dynamic Metric: 0.4305343511450382\n",
    "Distinct-2 Dynamic Metric: 0.7803163444639719\n",
    "Distinct-2 Not Dynamic Metric: 0.749618320610687\n",
    "Distinct-3 Dynamic Metric: 0.8822495606326889\n",
    "Distinct-3 Not Dynamic Metric: 0.8473282442748091\n",
    "Distinct-1 Dynamic Metric: 0.47771836007130125\n",
    "Distinct-1 Not Dynamic Metric: 0.42835365853658536\n",
    "Distinct-2 Dynamic Metric: 0.8110516934046346\n",
    "Distinct-2 Not Dynamic Metric: 0.7591463414634146\n",
    "Distinct-3 Dynamic Metric: 0.9162210338680927\n",
    "Distinct-3 Not Dynamic Metric: 0.8551829268292683\n",
    "Distinct-1 Dynamic Metric: 0.47766323024054985\n",
    "Distinct-1 Not Dynamic Metric: 0.458528951486698\n",
    "Distinct-2 Dynamic Metric: 0.8384879725085911\n",
    "Distinct-2 Not Dynamic Metric: 0.8184663536776213\n",
    "Distinct-3 Dynamic Metric: 0.9312714776632303\n",
    "Distinct-3 Not Dynamic Metric: 0.9061032863849765\n",
    "Distinct-1 Dynamic Metric: 0.4790697674418605\n",
    "Distinct-1 Not Dynamic Metric: 0.444794952681388\n",
    "Distinct-2 Dynamic Metric: 0.7984496124031008\n",
    "Distinct-2 Not Dynamic Metric: 0.750788643533123\n",
    "Distinct-3 Dynamic Metric: 0.8945736434108527\n",
    "Distinct-3 Not Dynamic Metric: 0.8659305993690851"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Quantitative Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "print(all_distinct_n_scores_dynamic)\n",
    "print(all_distinct_n_scores_not_dynamic)\n",
    "df_dynamic = pd.DataFrame(all_distinct_n_scores_dynamic)\n",
    "df_not_dynamic = pd.DataFrame(all_distinct_n_scores_not_dynamic)\n",
    "\n",
    "# Flatten the list of lists\n",
    "flattened_data = [sum(sublist, []) for sublist in all_distinct_n_scores_dynamic]\n",
    "# Assuming that each sublist has the same length, get the number of columns\n",
    "num_columns = len(flattened_data[0])\n",
    "\n",
    "# Create a DataFrame, where each column corresponds to the position in the sublists\n",
    "df = pd.DataFrame(flattened_data, columns=[f'Distinct-{(i % 3) + 1}' for i in range(num_columns)])\n",
    "print(df)\n",
    "# Now calculate the mean for each column\n",
    "means_dynamic = df.mean()\n",
    "print(\"Means Dynamic: \", means_dynamic)\n",
    "\n",
    "# Flatten the list of lists\n",
    "flattened_data = [sum(sublist, []) for sublist in all_distinct_n_scores_not_dynamic]\n",
    "# Assuming that each sublist has the same length, get the number of columns\n",
    "num_columns = len(flattened_data[0])\n",
    "\n",
    "# Create a DataFrame, where each column corresponds to the position in the sublists\n",
    "df = pd.DataFrame(flattened_data, columns=[f'Distinct-{(i % 3) + 1}' for i in range(num_columns)])\n",
    "print(df)\n",
    "# Now calculate the mean for each column\n",
    "means_not_dynamic = df.mean()\n",
    "print(\"Means not dynamic: \", means_not_dynamic)\n",
    "\n",
    "y_dynamic_1 = means_dynamic[::3]\n",
    "y_dynamic_2 = means_dynamic[1::3]\n",
    "y_dynamic_3 = means_dynamic[2::3]\n",
    "\n",
    "y_not_dynamic_1 = means_not_dynamic[::3]\n",
    "y_not_dynamic_2 = means_not_dynamic[1::3]\n",
    "y_not_dynamic_3 = means_not_dynamic[2::3]\n",
    "\n",
    "x = range(1, 11)\n",
    "\n",
    "# Create subplots\n",
    "fig, ax = plt.subplots(1, 3, figsize=(18, 6))  # Adjust figsize as needed\n",
    "\n",
    "# Plot data with labels\n",
    "ax[0].plot(x, y_dynamic_1, label='Dynamic Inputs')\n",
    "ax[0].plot(x, y_not_dynamic_1, label='Fixed Inputs')\n",
    "ax[1].plot(x, y_dynamic_2, label='Dynamic Inputs')\n",
    "ax[1].plot(x, y_not_dynamic_2, label='Fixed Inputs')\n",
    "ax[2].plot(x, y_dynamic_3, label='Dynamic Inputs')\n",
    "ax[2].plot(x, y_not_dynamic_3, label='Fixed Inputs')\n",
    "\n",
    "# Set labels and titles with increased font size\n",
    "for i in range(3):\n",
    "    ax[i].set_xlabel('Number of conversations regenerated', fontsize=18)\n",
    "    ax[i].set_ylabel(f'Distinct-{i+1} Scores', fontsize=18)\n",
    "    ax[i].tick_params(axis='both', which='major', labelsize=18)\n",
    "    ax[i].set_ylim([0.3,1])\n",
    "    ax[i].legend(fontsize=18)\n",
    "\n",
    "# ax[0].set_title('Comparison Distinct-1 scores with/without dynamic pieces', fontsize=16)\n",
    "# ax[1].set_title('Comparison Distinct-2 scores with/without dynamic pieces', fontsize=16)\n",
    "# ax[2].set_title('Comparison Distinct-3 scores with/without dynamic pieces', fontsize=16)\n",
    "\n",
    "# Add a general title\n",
    "fig.suptitle('Comparison of Distinct-N Scores with and without Dynamic Inputs', fontsize=22)\n",
    "\n",
    "# Adjust the layout\n",
    "plt.tight_layout()  # rect to make space for the suptitle\n",
    "plt.savefig(\"figs/distinct_n_score_comparison\" + \".pdf\")\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "perso",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
